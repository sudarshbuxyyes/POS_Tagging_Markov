{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5ivz0bXCUZG",
        "outputId": "6d043640-124a-4fdd-9d58-bb1e1418f186"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import words\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import tokenize\n",
        "from nltk.tag import pos_tag\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N4Gd3AeP2Pqt"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUheMyOe5zuh",
        "outputId": "daba412f-56e8-4983-f6e0-458d149f7802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "YTdWR58d5-JJ",
        "outputId": "5abdec10-73a5-448a-c608-7ba6a2fbd78f"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f9290ae192fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/MyDive/POS_items/test.words'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mlisting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlisting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/MyDive/POS_items/test.words'"
          ]
        }
      ],
      "source": [
        "with open('/content/drive/My Drive/MyDive/POS_items/test.words', 'r') as f:\n",
        "  listing = f.readlines()\n",
        "listing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Idc0s3IXC9LI"
      },
      "outputs": [],
      "source": [
        "def preprocessing(str):\n",
        "    #stopword removal\n",
        "    Stop = stopwords.words('english')\n",
        "    #remove punctuation\n",
        "    no_punc = [char for char in str if char not in string.punctuation]\n",
        "    no_punc = ''.join(no_punc)\n",
        "    #add word lemmatization.\n",
        "    \n",
        "    #return ' '.join([word for word in no_punc.split() if (word.lower() not in Stop)])\n",
        "    return ' '.join([word for word in no_punc.split()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4IzY0ZEftk_V"
      },
      "outputs": [],
      "source": [
        "def pos_tagging(s):\n",
        "    nopunc_sentence = preprocessing(s)\n",
        "    print(nopunc_sentence)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tags = pos_tag(nltk.word_tokenize(nopunc_sentence))\n",
        "    dict_tag = {'NN':[], 'VB':[], 'OTH':[]} #only three categories at the moment, can add all categories coming from pos_tag programmatically.\n",
        "    for tag in tags:\n",
        "        if tag[1] in [\"NN\",\"NNS\",\"NNP\",\"NNPS\"]: #NN-singular noun, NNS- noun plural, NNP-proper noun singular, NNPS- proper noun plural.\n",
        "            dict_tag['NN'].append(tag[0])\n",
        "        elif tag[1] in [\"VB\",\"VBD\",\"VBG\",\"VBN\",\"VBP\",\"VBZ\"]: #VB: verb in base form, VBG: verb in present participle, VBN: past participle taken, VBZ: verb singular, present, non-3rd person take, VBP:verb, singular present\n",
        "            dict_tag['VB'].append(tag[0])\n",
        "        else:\n",
        "            dict_tag['OTH'].append(tag[0])\n",
        "    return dict_tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-p_X2iLuKvE",
        "outputId": "ba5c45a9-d8b4-4c78-c06b-631c0c8ed748"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You should be ashamed of yourself for slandering Newcastle United\n",
            "{'NN': ['Newcastle', 'United'], 'VB': ['be', 'ashamed', 'slandering'], 'OTH': ['You', 'should', 'of', 'yourself', 'for']}\n"
          ]
        }
      ],
      "source": [
        "string2 = \"You should be ashamed of yourself! for slandering Newcastle United\"\n",
        "tags2 = pos_tagging(string2)\n",
        "print(tags2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_xpZH7oQ8c2",
        "outputId": "ee89a7b8-34f1-4e72-825d-cc0a9a025f34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You should be ashamed of yourself for slandering Newcastle United\n"
          ]
        }
      ],
      "source": [
        "print(preprocessing(string2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obURUE02wPX7",
        "outputId": "be19dde0-e329-48aa-db27-b61b0c4b6e21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['You', 'should', 'be', 'ashamed', 'of', 'yourself', 'for', 'slandering', 'Newcastle', 'United']\n",
            "You should be ashamed of yourself for slandering Newcastle United\n",
            "You should be ashamed of yourself for slandering Newcastle United\n",
            "{'NN': ['Newcastle', 'United'], 'VB': ['be', 'ashamed', 'slandering'], 'OTH': ['You', 'should', 'of', 'yourself', 'for']}\n",
            "You should be ashamed of yourself for slandering Newcastle United\n",
            "{'NN': ['Newcastle', 'United'], 'VB': ['be', 'ashamed', 'slandering'], 'OTH': ['You', 'should', 'of', 'yourself', 'for']}\n",
            "You should be ashamed of yourself for slandering Newcastle United\n",
            "{'NN': ['Newcastle', 'United'], 'VB': ['be', 'ashamed', 'slandering'], 'OTH': ['You', 'should', 'of', 'yourself', 'for']}\n"
          ]
        }
      ],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "list2= nltk.word_tokenize(preprocessing(string2))\n",
        "lemmatized = ' '.join([lemmatizer.lemmatize(w) for w in list2])\n",
        "print(list2)\n",
        "print(lemmatized)\n",
        "print(pos_tagging(lemmatized))\n",
        "print(pos_tagging(preprocessing(string2)))\n",
        "print(pos_tagging(string2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-qAoa7qw_NU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMHDAI0v2uoq",
        "outputId": "4fb4afbb-1780-4c02-8f41-524ffd18b98a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.2 0.2 0.6]\n",
            " [0.4 0.3 0.3]\n",
            " [0.2 0.3 0.5]]\n"
          ]
        }
      ],
      "source": [
        "m = np.matrix('0.2 0.2 0.6;0.4 0.3 0.3;0.2 0.3 0.5')\n",
        "print(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqKsY30cOLob"
      },
      "source": [
        "Generating transition and emission matrices -> tarini_HMM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gsDacBixOLVo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import string\n",
        "from collections import defaultdict\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jucr5QOPOQqU"
      },
      "outputs": [],
      "source": [
        "#Initialization\n",
        "\n",
        "setPunctuation = set(string.punctuation)\n",
        "suffixNoun = [\"action\", \"age\", \"ance\", \"cy\", \"dom\", \"ee\", \"ence\", \"er\", \"hood\", \"ion\", \"ism\", \"ist\", \"ity\", \"ling\", \"ment\", \"ness\", \"or\", \"ry\", \"scape\", \"ship\", \"ty\"]\n",
        "suffixVerb = [\"ate\", \"ify\", \"ise\", \"ize\"]\n",
        "suffixAdjective = [\"able\", \"ese\", \"ful\", \"i\", \"ian\", \"ible\", \"ic\", \"ish\", \"ive\", \"less\", \"ly\", \"ous\"]\n",
        "suffixAdverb = [\"ward\", \"wards\", \"wise\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Ook1tj2wOWsk"
      },
      "outputs": [],
      "source": [
        "# preprocessing datasets\n",
        "\n",
        "def testingDataSet_preProcessing(vocabulary, file):\n",
        "    preprossed = []\n",
        "    \n",
        "    with open(file, \"r\") as f:\n",
        "        for index, word in enumerate(f):\n",
        "            if not word.split():\n",
        "                word = \"--n--\"\n",
        "                preprossed.append(word)\n",
        "\n",
        "            elif word.strip() not in vocabulary:\n",
        "                word = tagAllotement(word)\n",
        "                preprossed.append(word)\n",
        "\n",
        "            else:\n",
        "                preprossed.append(word.strip())\n",
        "\n",
        "    return preprossed\n",
        "def tagAllotement(word):\n",
        "    if any(char.isdigit() for char in word):\n",
        "        return \"--unk_digit--\"\n",
        "\n",
        "    elif any(char in setPunctuation for char in word):\n",
        "        return \"--unk_punct--\"\n",
        "\n",
        "    elif any(char.isupper() for char in word):\n",
        "        return \"--unk_upper--\"\n",
        "\n",
        "    elif any(word.endswith(suffix) for suffix in suffixNoun):\n",
        "        return \"--unk_noun--\"\n",
        "\n",
        "    elif any(word.endswith(suffix) for suffix in suffixVerb):\n",
        "        return \"--unk_verb--\"\n",
        "\n",
        "    elif any(word.endswith(suffix) for suffix in suffixAdjective):\n",
        "        return \"--unk_adj--\"\n",
        "\n",
        "    elif any(word.endswith(suffix) for suffix in suffixAdverb):\n",
        "        return \"--unk_adv--\"\n",
        "    return \"--unk--\"\n",
        "\n",
        "def preprocessWord(wordTagPair, vocabulary): \n",
        "    if not wordTagPair.split():\n",
        "        word = \"--n--\"\n",
        "        tag = \"--s--\"\n",
        "        return word, tag\n",
        "    else:\n",
        "        word,tag = wordTagPair.split()\n",
        "        if word not in vocabulary: \n",
        "            word = tagAllotement(word)\n",
        "        return word, tag\n",
        "    return None "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mIY4hsziOjBd"
      },
      "outputs": [],
      "source": [
        "vocabulary = {}  \n",
        "\n",
        "with open(\"WSJ_02-21.pos\", 'r') as file:\n",
        "    trainingDataset = file.readlines()\n",
        "\n",
        "with open(\"WSJ_24.pos\", 'r') as file:\n",
        "    testingDataset = file.readlines()\n",
        "    \n",
        "with open(\"hmm_vocab.txt\", 'r') as file:\n",
        "    voc = file.read().split('\\n')\n",
        "\n",
        "i = 0\n",
        "for word in voc:\n",
        "    vocabulary[word] = i\n",
        "    i+=1\n",
        "    \n",
        "#preprocess testingDataSet\n",
        "preprocessedTestingData = testingDataSet_preProcessing(vocabulary, \"test.words\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvjneGXAb-2m",
        "outputId": "4407ba6e-b628-4894-ef28-e64bdc5c9a5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'!': 0,\n",
              " '#': 1,\n",
              " '$': 2,\n",
              " '%': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " \"''\": 6,\n",
              " \"'40s\": 7,\n",
              " \"'60s\": 8,\n",
              " \"'70s\": 9,\n",
              " \"'80s\": 10,\n",
              " \"'86\": 11,\n",
              " \"'90s\": 12,\n",
              " \"'N\": 13,\n",
              " \"'S\": 14,\n",
              " \"'d\": 15,\n",
              " \"'em\": 16,\n",
              " \"'ll\": 17,\n",
              " \"'m\": 18,\n",
              " \"'n'\": 19,\n",
              " \"'re\": 20,\n",
              " \"'s\": 21,\n",
              " \"'til\": 22,\n",
              " \"'ve\": 23,\n",
              " '(': 24,\n",
              " ')': 25,\n",
              " ',': 26,\n",
              " '-': 27,\n",
              " '--': 28,\n",
              " '--n--': 29,\n",
              " '--unk--': 30,\n",
              " '--unk_adj--': 31,\n",
              " '--unk_adv--': 32,\n",
              " '--unk_digit--': 33,\n",
              " '--unk_noun--': 34,\n",
              " '--unk_punct--': 35,\n",
              " '--unk_upper--': 36,\n",
              " '--unk_verb--': 37,\n",
              " '.': 38,\n",
              " '...': 39,\n",
              " '0.01': 40,\n",
              " '0.0108': 41,\n",
              " '0.02': 42,\n",
              " '0.03': 43,\n",
              " '0.05': 44,\n",
              " '0.1': 45,\n",
              " '0.10': 46,\n",
              " '0.12': 47,\n",
              " '0.13': 48,\n",
              " '0.15': 49,\n",
              " '0.17': 50,\n",
              " '0.19': 51,\n",
              " '0.2': 52,\n",
              " '0.24': 53,\n",
              " '0.25': 54,\n",
              " '0.3': 55,\n",
              " '0.32': 56,\n",
              " '0.375': 57,\n",
              " '0.4': 58,\n",
              " '0.43': 59,\n",
              " '0.45': 60,\n",
              " '0.5': 61,\n",
              " '0.53': 62,\n",
              " '0.59': 63,\n",
              " '0.6': 64,\n",
              " '0.60': 65,\n",
              " '0.7': 66,\n",
              " '0.71': 67,\n",
              " '0.75': 68,\n",
              " '0.8': 69,\n",
              " '0.88': 70,\n",
              " '0.9': 71,\n",
              " '0.94': 72,\n",
              " '0.95': 73,\n",
              " '1': 74,\n",
              " '1,000': 75,\n",
              " '1,012': 76,\n",
              " '1,015': 77,\n",
              " '1,040': 78,\n",
              " '1,050': 79,\n",
              " '1,100': 80,\n",
              " '1,111': 81,\n",
              " '1,150,000': 82,\n",
              " '1,200': 83,\n",
              " '1,250': 84,\n",
              " '1,250,000': 85,\n",
              " '1,300': 86,\n",
              " '1,365,226': 87,\n",
              " '1,400': 88,\n",
              " '1,500': 89,\n",
              " '1,600': 90,\n",
              " '1,700': 91,\n",
              " '1,750': 92,\n",
              " '1,800': 93,\n",
              " '1,828,000': 94,\n",
              " '1,850': 95,\n",
              " '1,859': 96,\n",
              " '1,900': 97,\n",
              " '1-2-3': 98,\n",
              " '1-for-10': 99,\n",
              " '1-to-1': 100,\n",
              " '1.0': 101,\n",
              " '1.01': 102,\n",
              " '1.02': 103,\n",
              " '1.03': 104,\n",
              " '1.04': 105,\n",
              " '1.05': 106,\n",
              " '1.06': 107,\n",
              " '1.07': 108,\n",
              " '1.08': 109,\n",
              " '1.09': 110,\n",
              " '1.1': 111,\n",
              " '1.10': 112,\n",
              " '1.11': 113,\n",
              " '1.12': 114,\n",
              " '1.125': 115,\n",
              " '1.13': 116,\n",
              " '1.14': 117,\n",
              " '1.15': 118,\n",
              " '1.16': 119,\n",
              " '1.17': 120,\n",
              " '1.18': 121,\n",
              " '1.19': 122,\n",
              " '1.2': 123,\n",
              " '1.20': 124,\n",
              " '1.21': 125,\n",
              " '1.22': 126,\n",
              " '1.23': 127,\n",
              " '1.24': 128,\n",
              " '1.25': 129,\n",
              " '1.26': 130,\n",
              " '1.27': 131,\n",
              " '1.28': 132,\n",
              " '1.29': 133,\n",
              " '1.3': 134,\n",
              " '1.30': 135,\n",
              " '1.31': 136,\n",
              " '1.32': 137,\n",
              " '1.34': 138,\n",
              " '1.35': 139,\n",
              " '1.36': 140,\n",
              " '1.37': 141,\n",
              " '1.375': 142,\n",
              " '1.38': 143,\n",
              " '1.39': 144,\n",
              " '1.4': 145,\n",
              " '1.40': 146,\n",
              " '1.41': 147,\n",
              " '1.42': 148,\n",
              " '1.43': 149,\n",
              " '1.44': 150,\n",
              " '1.45': 151,\n",
              " '1.46': 152,\n",
              " '1.47': 153,\n",
              " '1.48': 154,\n",
              " '1.49': 155,\n",
              " '1.5': 156,\n",
              " '1.50': 157,\n",
              " '1.51': 158,\n",
              " '1.52': 159,\n",
              " '1.53': 160,\n",
              " '1.54': 161,\n",
              " '1.55': 162,\n",
              " '1.56': 163,\n",
              " '1.5753': 164,\n",
              " '1.5765': 165,\n",
              " '1.5795': 166,\n",
              " '1.58': 167,\n",
              " '1.5820': 168,\n",
              " '1.5825': 169,\n",
              " '1.59': 170,\n",
              " '1.5920': 171,\n",
              " '1.6': 172,\n",
              " '1.60': 173,\n",
              " '1.6030': 174,\n",
              " '1.6055': 175,\n",
              " '1.6145': 176,\n",
              " '1.62': 177,\n",
              " '1.625': 178,\n",
              " '1.63': 179,\n",
              " '1.64': 180,\n",
              " '1.65': 181,\n",
              " '1.66': 182,\n",
              " '1.67': 183,\n",
              " '1.69': 184,\n",
              " '1.7': 185,\n",
              " '1.70': 186,\n",
              " '1.71': 187,\n",
              " '1.72': 188,\n",
              " '1.73': 189,\n",
              " '1.74': 190,\n",
              " '1.75': 191,\n",
              " '1.76': 192,\n",
              " '1.77': 193,\n",
              " '1.78': 194,\n",
              " '1.79': 195,\n",
              " '1.8': 196,\n",
              " '1.80': 197,\n",
              " '1.81': 198,\n",
              " '1.82': 199,\n",
              " '1.8200': 200,\n",
              " '1.83': 201,\n",
              " '1.8300': 202,\n",
              " '1.8340': 203,\n",
              " '1.8353': 204,\n",
              " '1.8355': 205,\n",
              " '1.84': 206,\n",
              " '1.8400': 207,\n",
              " '1.8415': 208,\n",
              " '1.8470': 209,\n",
              " '1.8485': 210,\n",
              " '1.85': 211,\n",
              " '1.8578': 212,\n",
              " '1.86': 213,\n",
              " '1.8667': 214,\n",
              " '1.8685': 215,\n",
              " '1.87': 216,\n",
              " '1.875': 217,\n",
              " '1.88': 218,\n",
              " '1.89': 219,\n",
              " '1.9': 220,\n",
              " '1.90': 221,\n",
              " '1.91': 222,\n",
              " '1.92': 223,\n",
              " '1.93': 224,\n",
              " '1.94': 225,\n",
              " '1.95': 226,\n",
              " '10': 227,\n",
              " '10,000': 228,\n",
              " '10-11': 229,\n",
              " '10-a-share': 230,\n",
              " '10-cent-a-share': 231,\n",
              " '10-month': 232,\n",
              " '10-year': 233,\n",
              " '10-year-old': 234,\n",
              " '10.03': 235,\n",
              " '10.05': 236,\n",
              " '10.1': 237,\n",
              " '10.14': 238,\n",
              " '10.2': 239,\n",
              " '10.3': 240,\n",
              " '10.35': 241,\n",
              " '10.37': 242,\n",
              " '10.4': 243,\n",
              " '10.48': 244,\n",
              " '10.5': 245,\n",
              " '10.59': 246,\n",
              " '10.6': 247,\n",
              " '10.625': 248,\n",
              " '10.7': 249,\n",
              " '10.77': 250,\n",
              " '10.8': 251,\n",
              " '10.9': 252,\n",
              " '100': 253,\n",
              " '100,000': 254,\n",
              " '100-Share': 255,\n",
              " '100-share': 256,\n",
              " '100-stock': 257,\n",
              " '100.2': 258,\n",
              " '100.4': 259,\n",
              " '101': 260,\n",
              " '101.4': 261,\n",
              " '102': 262,\n",
              " '102.1': 263,\n",
              " '102.625': 264,\n",
              " '103': 265,\n",
              " '103,000': 266,\n",
              " '104': 267,\n",
              " '105': 268,\n",
              " '105.4': 269,\n",
              " '106': 270,\n",
              " '107': 271,\n",
              " '108': 272,\n",
              " '108.4': 273,\n",
              " '109': 274,\n",
              " '109.85': 275,\n",
              " '10:30': 276,\n",
              " '10:40': 277,\n",
              " '10\\\\/32': 278,\n",
              " '10th': 279,\n",
              " '11': 280,\n",
              " '11,000': 281,\n",
              " '11.04': 282,\n",
              " '11.1': 283,\n",
              " '11.2': 284,\n",
              " '11.25': 285,\n",
              " '11.3': 286,\n",
              " '11.38': 287,\n",
              " '11.4': 288,\n",
              " '11.5': 289,\n",
              " '11.53': 290,\n",
              " '11.6': 291,\n",
              " '11.60': 292,\n",
              " '11.625': 293,\n",
              " '11.7': 294,\n",
              " '11.8': 295,\n",
              " '11.9': 296,\n",
              " '11.95': 297,\n",
              " '110': 298,\n",
              " '110,000': 299,\n",
              " '110.6': 300,\n",
              " '111': 301,\n",
              " '111.48': 302,\n",
              " '112': 303,\n",
              " '112.5': 304,\n",
              " '113': 305,\n",
              " '114': 306,\n",
              " '114.3': 307,\n",
              " '114.4': 308,\n",
              " '115': 309,\n",
              " '116': 310,\n",
              " '117': 311,\n",
              " '117.3': 312,\n",
              " '118': 313,\n",
              " '119': 314,\n",
              " '119.88': 315,\n",
              " '11\\\\/16': 316,\n",
              " '11\\\\/32': 317,\n",
              " '11th': 318,\n",
              " '12': 319,\n",
              " '12,000': 320,\n",
              " '12,500': 321,\n",
              " '12-month': 322,\n",
              " '12-year': 323,\n",
              " '12-year-old': 324,\n",
              " '12.2': 325,\n",
              " '12.3': 326,\n",
              " '12.4': 327,\n",
              " '12.45': 328,\n",
              " '12.5': 329,\n",
              " '12.6': 330,\n",
              " '12.7': 331,\n",
              " '12.75': 332,\n",
              " '12.8': 333,\n",
              " '12.9': 334,\n",
              " '12.95': 335,\n",
              " '120': 336,\n",
              " '120,000': 337,\n",
              " '120-day': 338,\n",
              " '120.7': 339,\n",
              " '121': 340,\n",
              " '122': 341,\n",
              " '122.7': 342,\n",
              " '123': 343,\n",
              " '123.5': 344,\n",
              " '1230.80': 345,\n",
              " '124': 346,\n",
              " '124,875': 347,\n",
              " '1247.87': 348,\n",
              " '125': 349,\n",
              " '125,000': 350,\n",
              " '1254.27': 351,\n",
              " '127': 352,\n",
              " '127.5': 353,\n",
              " '128': 354,\n",
              " '129.49': 355,\n",
              " '12:01': 356,\n",
              " '12\\\\/32': 357,\n",
              " '13': 358,\n",
              " '13,000': 359,\n",
              " '13,120': 360,\n",
              " '13-week': 361,\n",
              " '13.05': 362,\n",
              " '13.1': 363,\n",
              " '13.2': 364,\n",
              " '13.32': 365,\n",
              " '13.35': 366,\n",
              " '13.4': 367,\n",
              " '13.5': 368,\n",
              " '13.50': 369,\n",
              " '13.6': 370,\n",
              " '13.625': 371,\n",
              " '13.7': 372,\n",
              " '13.71': 373,\n",
              " '13.75': 374,\n",
              " '13.8': 375,\n",
              " '13.94': 376,\n",
              " '130': 377,\n",
              " '130,000': 378,\n",
              " '131': 379,\n",
              " '132': 380,\n",
              " '132.8': 381,\n",
              " '133': 382,\n",
              " '134': 383,\n",
              " '134.8': 384,\n",
              " '135': 385,\n",
              " '136': 386,\n",
              " '136.4': 387,\n",
              " '137': 388,\n",
              " '137.6': 389,\n",
              " '138': 390,\n",
              " '139': 391,\n",
              " '13\\\\/16': 392,\n",
              " '13th': 393,\n",
              " '14': 394,\n",
              " '14,000': 395,\n",
              " '14-year-old': 396,\n",
              " '14.06': 397,\n",
              " '14.1': 398,\n",
              " '14.2': 399,\n",
              " '14.25': 400,\n",
              " '14.3': 401,\n",
              " '14.5': 402,\n",
              " '14.6': 403,\n",
              " '14.7': 404,\n",
              " '14.75': 405,\n",
              " '14.8': 406,\n",
              " '140': 407,\n",
              " '140,000': 408,\n",
              " '141': 409,\n",
              " '141.45': 410,\n",
              " '141.52': 411,\n",
              " '141.55': 412,\n",
              " '141.65': 413,\n",
              " '141.70': 414,\n",
              " '141.80': 415,\n",
              " '141.90': 416,\n",
              " '142': 417,\n",
              " '142.10': 418,\n",
              " '142.43': 419,\n",
              " '142.70': 420,\n",
              " '142.75': 421,\n",
              " '142.85': 422,\n",
              " '143': 423,\n",
              " '144': 424,\n",
              " '145': 425,\n",
              " '146': 426,\n",
              " '146.8': 427,\n",
              " '1466.29': 428,\n",
              " '148': 429,\n",
              " '149': 430,\n",
              " '14th': 431,\n",
              " '15': 432,\n",
              " '15,000': 433,\n",
              " '15-a-share': 434,\n",
              " '15-year': 435,\n",
              " '15.06': 436,\n",
              " '15.1': 437,\n",
              " '15.125': 438,\n",
              " '15.2': 439,\n",
              " '15.25': 440,\n",
              " '15.3': 441,\n",
              " '15.375': 442,\n",
              " '15.5': 443,\n",
              " '15.50': 444,\n",
              " '15.6': 445,\n",
              " '15.625': 446,\n",
              " '15.7': 447,\n",
              " '15.72': 448,\n",
              " '15.75': 449,\n",
              " '15.80': 450,\n",
              " '15.82': 451,\n",
              " '15.9': 452,\n",
              " '15.97': 453,\n",
              " '150': 454,\n",
              " '150,000': 455,\n",
              " '150-member': 456,\n",
              " '150.3': 457,\n",
              " '151': 458,\n",
              " '151,000': 459,\n",
              " '151.20': 460,\n",
              " '153': 461,\n",
              " '154': 462,\n",
              " '154.2': 463,\n",
              " '155': 464,\n",
              " '155,650,000': 465,\n",
              " '156': 466,\n",
              " '156.7': 467,\n",
              " '157': 468,\n",
              " '158': 469,\n",
              " '15\\\\/16': 470,\n",
              " '15\\\\/32': 471,\n",
              " '16': 472,\n",
              " '16,000': 473,\n",
              " '16-bit': 474,\n",
              " '16.1': 475,\n",
              " '16.2': 476,\n",
              " '16.3': 477,\n",
              " '16.375': 478,\n",
              " '16.4': 479,\n",
              " '16.40': 480,\n",
              " '16.5': 481,\n",
              " '16.6': 482,\n",
              " '16.75': 483,\n",
              " '16.9': 484,\n",
              " '16.95': 485,\n",
              " '160': 486,\n",
              " '160,000': 487,\n",
              " '161': 488,\n",
              " '161.1': 489,\n",
              " '161.5': 490,\n",
              " '162': 491,\n",
              " '162,000': 492,\n",
              " '163': 493,\n",
              " '163-member': 494,\n",
              " '164,830,000': 495,\n",
              " '165': 496,\n",
              " '166': 497,\n",
              " '166,900,000': 498,\n",
              " '166.9': 499,\n",
              " '167': 500,\n",
              " '168': 501,\n",
              " '16\\\\/32': 502,\n",
              " '16th': 503,\n",
              " '17': 504,\n",
              " '17,000': 505,\n",
              " '17-store': 506,\n",
              " '17.01': 507,\n",
              " '17.1': 508,\n",
              " '17.2': 509,\n",
              " '17.3': 510,\n",
              " '17.4': 511,\n",
              " '17.5': 512,\n",
              " '17.50': 513,\n",
              " '17.6': 514,\n",
              " '17.8': 515,\n",
              " '17.9': 516,\n",
              " '17.95': 517,\n",
              " '170': 518,\n",
              " '170,330,000': 519,\n",
              " '170.4': 520,\n",
              " '171': 521,\n",
              " '172': 522,\n",
              " '172.2': 523,\n",
              " '172.5': 524,\n",
              " '173.1': 525,\n",
              " '174': 526,\n",
              " '175': 527,\n",
              " '175,000': 528,\n",
              " '176': 529,\n",
              " '176,100,000': 530,\n",
              " '177': 531,\n",
              " '177.5': 532,\n",
              " '178': 533,\n",
              " '178.375': 534,\n",
              " '178.5': 535,\n",
              " '178.9': 536,\n",
              " '179': 537,\n",
              " '17\\\\/32': 538,\n",
              " '17th-century': 539,\n",
              " '18': 540,\n",
              " '18,000': 541,\n",
              " '18.1': 542,\n",
              " '18.375': 543,\n",
              " '18.4': 544,\n",
              " '18.5': 545,\n",
              " '18.50': 546,\n",
              " '18.65': 547,\n",
              " '18.7': 548,\n",
              " '18.75': 549,\n",
              " '18.9': 550,\n",
              " '18.95': 551,\n",
              " '180': 552,\n",
              " '180,000': 553,\n",
              " '181': 554,\n",
              " '182': 555,\n",
              " '182-day': 556,\n",
              " '184': 557,\n",
              " '185': 558,\n",
              " '186': 559,\n",
              " '1868': 560,\n",
              " '187': 561,\n",
              " '188': 562,\n",
              " '189': 563,\n",
              " '1890s': 564,\n",
              " '18\\\\/32': 565,\n",
              " '18th': 566,\n",
              " '18th-century': 567,\n",
              " '19': 568,\n",
              " '19-month': 569,\n",
              " '19-month-old': 570,\n",
              " '19.2': 571,\n",
              " '19.25': 572,\n",
              " '19.5': 573,\n",
              " '19.50': 574,\n",
              " '19.6': 575,\n",
              " '19.7': 576,\n",
              " '19.95': 577,\n",
              " '190': 578,\n",
              " '190-point': 579,\n",
              " '190.58': 580,\n",
              " '190.58-point': 581,\n",
              " '1900': 582,\n",
              " '1900s': 583,\n",
              " '1906': 584,\n",
              " '1908': 585,\n",
              " '191.75': 586,\n",
              " '192.5': 587,\n",
              " '1920s': 588,\n",
              " '1926': 589,\n",
              " '1929': 590,\n",
              " '193': 591,\n",
              " '193.3': 592,\n",
              " '1930': 593,\n",
              " '1930s': 594,\n",
              " '1932': 595,\n",
              " '1935': 596,\n",
              " '1939': 597,\n",
              " '1940s': 598,\n",
              " '1942': 599,\n",
              " '1947': 600,\n",
              " '1948': 601,\n",
              " '1949': 602,\n",
              " '1950': 603,\n",
              " '1950s': 604,\n",
              " '1951': 605,\n",
              " '1953': 606,\n",
              " '1955': 607,\n",
              " '1956': 608,\n",
              " '1957': 609,\n",
              " '1958': 610,\n",
              " '1959': 611,\n",
              " '196': 612,\n",
              " '1960': 613,\n",
              " '1960s': 614,\n",
              " '1961': 615,\n",
              " '1962': 616,\n",
              " '1963': 617,\n",
              " '1964': 618,\n",
              " '1965': 619,\n",
              " '1966': 620,\n",
              " '1967': 621,\n",
              " '1968': 622,\n",
              " '1969': 623,\n",
              " '197': 624,\n",
              " '1970': 625,\n",
              " '1970s': 626,\n",
              " '1971': 627,\n",
              " '1972': 628,\n",
              " '1973': 629,\n",
              " '1974': 630,\n",
              " '1975': 631,\n",
              " '1976': 632,\n",
              " '1977': 633,\n",
              " '1978': 634,\n",
              " '1979': 635,\n",
              " '1979-80': 636,\n",
              " '198': 637,\n",
              " '198,120,000': 638,\n",
              " '1980': 639,\n",
              " '1980s': 640,\n",
              " '1981': 641,\n",
              " '1982': 642,\n",
              " '1982-83': 643,\n",
              " '1983': 644,\n",
              " '1984': 645,\n",
              " '1985': 646,\n",
              " '1986': 647,\n",
              " '1987': 648,\n",
              " '1987-88': 649,\n",
              " '1988': 650,\n",
              " '1989': 651,\n",
              " '1989-A': 652,\n",
              " '1989A': 653,\n",
              " '1989B': 654,\n",
              " '199': 655,\n",
              " '1990': 656,\n",
              " '1990-2002': 657,\n",
              " '1990-model': 658,\n",
              " '1990s': 659,\n",
              " '1991': 660,\n",
              " '1992': 661,\n",
              " '1993': 662,\n",
              " '1993-2009': 663,\n",
              " '1994': 664,\n",
              " '1995': 665,\n",
              " '1996': 666,\n",
              " '1997': 667,\n",
              " '1998': 668,\n",
              " '1999': 669,\n",
              " '19\\\\/32': 670,\n",
              " '19th': 671,\n",
              " '19th-century': 672,\n",
              " '1:11': 673,\n",
              " '1\\\\/2': 674,\n",
              " '1\\\\/2-year': 675,\n",
              " '1\\\\/32': 676,\n",
              " '1\\\\/4': 677,\n",
              " '1\\\\/8': 678,\n",
              " '2': 679,\n",
              " '2,000': 680,\n",
              " '2,002': 681,\n",
              " '2,064': 682,\n",
              " '2,100': 683,\n",
              " '2,120': 684,\n",
              " '2,202,000': 685,\n",
              " '2,205,000': 686,\n",
              " '2,250,000': 687,\n",
              " '2,360': 688,\n",
              " '2,400': 689,\n",
              " '2,500': 690,\n",
              " '2,700': 691,\n",
              " '2-for-1': 692,\n",
              " '2-to-1': 693,\n",
              " '2.01': 694,\n",
              " '2.02': 695,\n",
              " '2.03': 696,\n",
              " '2.04': 697,\n",
              " '2.06': 698,\n",
              " '2.07': 699,\n",
              " '2.08': 700,\n",
              " '2.09': 701,\n",
              " '2.1': 702,\n",
              " '2.10': 703,\n",
              " '2.125': 704,\n",
              " '2.14': 705,\n",
              " '2.15': 706,\n",
              " '2.17': 707,\n",
              " '2.19': 708,\n",
              " '2.2': 709,\n",
              " '2.21': 710,\n",
              " '2.22': 711,\n",
              " '2.23': 712,\n",
              " '2.25': 713,\n",
              " '2.26': 714,\n",
              " '2.27': 715,\n",
              " '2.28': 716,\n",
              " '2.29': 717,\n",
              " '2.3': 718,\n",
              " '2.30': 719,\n",
              " '2.32': 720,\n",
              " '2.33': 721,\n",
              " '2.34': 722,\n",
              " '2.35': 723,\n",
              " '2.36': 724,\n",
              " '2.375': 725,\n",
              " '2.38': 726,\n",
              " '2.4': 727,\n",
              " '2.40': 728,\n",
              " '2.41': 729,\n",
              " '2.44': 730,\n",
              " '2.45': 731,\n",
              " '2.46': 732,\n",
              " '2.5': 733,\n",
              " '2.5-mile': 734,\n",
              " '2.50': 735,\n",
              " '2.51': 736,\n",
              " '2.53': 737,\n",
              " '2.56': 738,\n",
              " '2.57': 739,\n",
              " '2.58': 740,\n",
              " '2.6': 741,\n",
              " '2.60': 742,\n",
              " '2.61': 743,\n",
              " '2.62': 744,\n",
              " '2.625': 745,\n",
              " '2.63': 746,\n",
              " '2.65': 747,\n",
              " '2.66': 748,\n",
              " '2.68': 749,\n",
              " '2.69': 750,\n",
              " '2.7': 751,\n",
              " '2.70': 752,\n",
              " '2.73': 753,\n",
              " '2.74': 754,\n",
              " '2.75': 755,\n",
              " '2.77': 756,\n",
              " '2.79': 757,\n",
              " '2.8': 758,\n",
              " '2.80': 759,\n",
              " '2.82': 760,\n",
              " '2.85': 761,\n",
              " '2.87': 762,\n",
              " '2.875': 763,\n",
              " '2.88': 764,\n",
              " '2.9': 765,\n",
              " '2.90': 766,\n",
              " '2.95': 767,\n",
              " '20': 768,\n",
              " '20,000': 769,\n",
              " '20-stock': 770,\n",
              " '20-year': 771,\n",
              " '20-year-old': 772,\n",
              " '20.125': 773,\n",
              " '20.3': 774,\n",
              " '20.42': 775,\n",
              " '20.5': 776,\n",
              " '20.6': 777,\n",
              " '20.75': 778,\n",
              " '20.9': 779,\n",
              " '200': 780,\n",
              " '200,000': 781,\n",
              " '200,000-share': 782,\n",
              " '2000': 783,\n",
              " '2001': 784,\n",
              " '2002': 785,\n",
              " '2003': 786,\n",
              " '2003-2005': 787,\n",
              " '2003\\\\/2007': 788,\n",
              " '2004': 789,\n",
              " '2005': 790,\n",
              " '2006': 791,\n",
              " '2007': 792,\n",
              " '2008': 793,\n",
              " '2008-2009': 794,\n",
              " '2009': 795,\n",
              " '2010': 796,\n",
              " '2011': 797,\n",
              " '2012': 798,\n",
              " '2013': 799,\n",
              " '2014': 800,\n",
              " '2015': 801,\n",
              " '2016': 802,\n",
              " '2018': 803,\n",
              " '2019': 804,\n",
              " '2020': 805,\n",
              " '2023': 806,\n",
              " '205': 807,\n",
              " '206': 808,\n",
              " '207': 809,\n",
              " '208': 810,\n",
              " '208.7': 811,\n",
              " '209,000': 812,\n",
              " '20th': 813,\n",
              " '21': 814,\n",
              " '21.1': 815,\n",
              " '21.125': 816,\n",
              " '21.2': 817,\n",
              " '21.3': 818,\n",
              " '21.4': 819,\n",
              " '21.44': 820,\n",
              " '21.5': 821,\n",
              " '21.6': 822,\n",
              " '21.7': 823,\n",
              " '21.8': 824,\n",
              " '210': 825,\n",
              " '213': 826,\n",
              " '2149.3': 827,\n",
              " '215': 828,\n",
              " '216': 829,\n",
              " '217': 830,\n",
              " '219': 831,\n",
              " '21\\\\/32': 832,\n",
              " '21st': 833,\n",
              " '22': 834,\n",
              " '22,000': 835,\n",
              " '22.125': 836,\n",
              " '22.25': 837,\n",
              " '22.4': 838,\n",
              " '22.5': 839,\n",
              " '22.50': 840,\n",
              " '22.6': 841,\n",
              " '22.78': 842,\n",
              " '22.8': 843,\n",
              " '22.9': 844,\n",
              " '220': 845,\n",
              " '220,000': 846,\n",
              " '2200': 847,\n",
              " '221': 848,\n",
              " '222': 849,\n",
              " '224': 850,\n",
              " '224,070,000': 851,\n",
              " '224.1': 852,\n",
              " '225': 853,\n",
              " '226.3': 854,\n",
              " '229': 855,\n",
              " '22\\\\/32': 856,\n",
              " '22nd': 857,\n",
              " '23': 858,\n",
              " '23,000': 859,\n",
              " '23.1': 860,\n",
              " '23.2': 861,\n",
              " '23.25': 862,\n",
              " '23.5': 863,\n",
              " '23.625': 864,\n",
              " '23.7': 865,\n",
              " '23.8': 866,\n",
              " '23.9': 867,\n",
              " '230': 868,\n",
              " '231': 869,\n",
              " '231-191': 870,\n",
              " '232': 871,\n",
              " '232.3': 872,\n",
              " '234': 873,\n",
              " '235': 874,\n",
              " '235.2': 875,\n",
              " '237,960,000': 876,\n",
              " '238': 877,\n",
              " '23\\\\/32': 878,\n",
              " '24': 879,\n",
              " '24,000': 880,\n",
              " '24-hour': 881,\n",
              " '24-month': 882,\n",
              " '24.2': 883,\n",
              " '24.25': 884,\n",
              " '24.4': 885,\n",
              " '24.5': 886,\n",
              " '24.8': 887,\n",
              " '24.875': 888,\n",
              " '24.9': 889,\n",
              " '240': 890,\n",
              " '240,000': 891,\n",
              " '242': 892,\n",
              " '244': 893,\n",
              " '245': 894,\n",
              " '246.6': 895,\n",
              " '247': 896,\n",
              " '248': 897,\n",
              " '24th': 898,\n",
              " '25': 899,\n",
              " '25,000': 900,\n",
              " '25-year-old': 901,\n",
              " '25.2': 902,\n",
              " '25.3': 903,\n",
              " '25.4': 904,\n",
              " '25.5': 905,\n",
              " '25.6': 906,\n",
              " '25.8': 907,\n",
              " '25.875': 908,\n",
              " '250': 909,\n",
              " '250,000': 910,\n",
              " '251': 911,\n",
              " '252': 912,\n",
              " '253': 913,\n",
              " '254': 914,\n",
              " '255': 915,\n",
              " '256.6': 916,\n",
              " '257.8': 917,\n",
              " '258': 918,\n",
              " '2596.72': 919,\n",
              " '25\\\\/32': 920,\n",
              " '25th': 921,\n",
              " '26': 922,\n",
              " '26,000': 923,\n",
              " '26-week': 924,\n",
              " '26-year-old': 925,\n",
              " '26.1': 926,\n",
              " '26.23': 927,\n",
              " '26.3': 928,\n",
              " '26.5': 929,\n",
              " '26.50': 930,\n",
              " '26.7': 931,\n",
              " '26.9': 932,\n",
              " '260': 933,\n",
              " '2603.48': 934,\n",
              " '2638.73': 935,\n",
              " '264': 936,\n",
              " '2643.65': 937,\n",
              " '2645.08': 938,\n",
              " '265': 939,\n",
              " '2653.28': 940,\n",
              " '2659.22': 941,\n",
              " '266': 942,\n",
              " '266.2': 943,\n",
              " '266.66': 944,\n",
              " '2662.91': 945,\n",
              " '267': 946,\n",
              " '268': 947,\n",
              " '2683.20': 948,\n",
              " '2689.14': 949,\n",
              " '269': 950,\n",
              " '26\\\\/32': 951,\n",
              " '27': 952,\n",
              " '27,000': 953,\n",
              " '27-year-old': 954,\n",
              " '27.1': 955,\n",
              " '27.5': 956,\n",
              " '27.6': 957,\n",
              " '27.7': 958,\n",
              " '27.8': 959,\n",
              " '27.9': 960,\n",
              " '270': 961,\n",
              " '271': 962,\n",
              " '273': 963,\n",
              " '274': 964,\n",
              " '275': 965,\n",
              " '275,000': 966,\n",
              " '276,334': 967,\n",
              " '276.8': 968,\n",
              " '278': 969,\n",
              " '279': 970,\n",
              " '2791.41': 971,\n",
              " '28': 972,\n",
              " '28,000': 973,\n",
              " '28.4': 974,\n",
              " '28.5': 975,\n",
              " '28.6': 976,\n",
              " '28.7': 977,\n",
              " '28.75': 978,\n",
              " '280': 979,\n",
              " '282': 980,\n",
              " '283.7': 981,\n",
              " '283.8': 982,\n",
              " '285': 983,\n",
              " '286': 984,\n",
              " '287': 985,\n",
              " '288': 986,\n",
              " '289': 987,\n",
              " '28\\\\/32': 988,\n",
              " '29': 989,\n",
              " '29-year-old': 990,\n",
              " '29.4': 991,\n",
              " '29.6': 992,\n",
              " '29.7': 993,\n",
              " '290': 994,\n",
              " '293': 995,\n",
              " '294': 996,\n",
              " '29\\\\/32': 997,\n",
              " '2\\\\/32': 998,\n",
              " '3': 999,\n",
              " ...}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-B3MIGY0Os1N"
      },
      "outputs": [],
      "source": [
        "def calcCounts(trainingDataset, vocabulary):\n",
        "    #countEmission - #(tag,word) pairs\n",
        "    #countTransition - #(tag,tag) pairs\n",
        "    #countTag - #tags\n",
        "    countEmission = defaultdict(int)\n",
        "    countTransition = defaultdict(int)\n",
        "    countTag = defaultdict(int)\n",
        "    \n",
        "    previousTag = '--s--' \n",
        "    index = 0 \n",
        "    \n",
        "    for wordTagPair in trainingDataset:\n",
        "        index+=1\n",
        "\n",
        "        word, tag = preprocessWord(wordTagPair, vocabulary)\n",
        "        \n",
        "        countTransition[(previousTag, tag)] += 1\n",
        "        countEmission[(tag, word)] += 1\n",
        "        countTag[tag] += 1\n",
        "        \n",
        "        previousTag = tag\n",
        "        \n",
        "    return countEmission, countTransition, countTag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DH_gVqwPOwa3"
      },
      "outputs": [],
      "source": [
        "countEmission, countTransition, countTag = calcCounts(trainingDataset, vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs2plfbxVHer",
        "outputId": "8161452b-cd14-43a0-d21d-e90386ab85ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "markovStates = sorted(countTag.keys())\n",
        "len(markovStates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zc7Q2CyCOq6H"
      },
      "outputs": [],
      "source": [
        "def calcTransitionMatrix(countTransition, countTag, epsilon, markovStates):\n",
        "    \n",
        "    numberStates = len(markovStates)\n",
        "    transitionMatrix = np.zeros((numberStates, numberStates))\n",
        "    tagTagPair = set(countTransition.keys())\n",
        "\n",
        "    for i in range(numberStates):\n",
        "        for j in range(numberStates):\n",
        "            countNextTag = 0\n",
        "            key = (markovStates[i],markovStates[j])\n",
        "            \n",
        "            if key in countTransition: \n",
        "                countNextTag = countTransition[key]\n",
        "                \n",
        "            countPreviousTag = countTag[key[0]]\n",
        "            transitionMatrix[i][j] = (countNextTag+epsilon)/(countPreviousTag+(numberStates*epsilon))\n",
        "\n",
        "    return transitionMatrix\n",
        "epsilon = 0.001\n",
        "transitionMatrix = calcTransitionMatrix(countTransition, countTag, epsilon, markovStates)\n",
        "def calcEmissionMatrix(countEmission, countTag, epsilon, markovStates, vocabulary):\n",
        "\n",
        "    numberStates = len(markovStates)\n",
        "    numberWords = len(vocabulary)\n",
        "    emissionMatrix = np.zeros((numberStates, numberWords))\n",
        "    tagWordPair = set(list(countEmission.keys()))\n",
        "    \n",
        "    for i in range(numberStates):\n",
        "        for j in range(numberWords):\n",
        "            countWord = 0\n",
        "            key =  (markovStates[i],vocabulary[j])\n",
        "\n",
        "            if key in countEmission: \n",
        "                countWord = countEmission[key]\n",
        "\n",
        "            countTags = countTag[key[0]]\n",
        "\n",
        "            emissionMatrix[i][j] = (countWord+epsilon)/(countTags+(epsilon*numberWords))\n",
        "\n",
        "    return emissionMatrix\n",
        "emissionMatrix = calcEmissionMatrix(countEmission, countTag, epsilon, markovStates,  list(vocabulary))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uNg2awRPKig"
      },
      "source": [
        "Viterbi Algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nMg7lQn_PNqt"
      },
      "outputs": [],
      "source": [
        "def viterbi_initialise(states, tag_counts, transitionMatrix, emissionMatrix, corpus, vocab):\n",
        "    n_tags = len(tag_counts)\n",
        "    best_probs = np.zeros((n_tags, len(corpus)),dtype = float)\n",
        "    best_paths = np.zeros((n_tags, len(corpus)), dtype = float)\n",
        "    #initialising best_probs and best_paths.\n",
        "\n",
        "    start_index = states.index(\"--s--\")\n",
        "    for i in range(n_tags):\n",
        "        if transitionMatrix[start_index, i]==0:\n",
        "            best_probs[i,0] = float('-inf')\n",
        "        else:\n",
        "            best_probs[i,0] = transitionMatrix[start_index,i] + emissionMatrix[i,vocab[corpus[0]]]\n",
        "    \n",
        "    return best_probs, best_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2EfCueNtazoD"
      },
      "outputs": [],
      "source": [
        "def preprocess(vocab, data_fp):\n",
        "    \"\"\"\n",
        "    Preprocess data\n",
        "    \"\"\"\n",
        "    orig = []\n",
        "    prep = []\n",
        "\n",
        "    # Read data\n",
        "    with open(data_fp, \"r\") as data_file:\n",
        "\n",
        "        for cnt, word in enumerate(data_file):\n",
        "\n",
        "            # End of sentence\n",
        "            if not word.split():\n",
        "                orig.append(word.strip())\n",
        "                word = \"--n--\"\n",
        "                prep.append(word)\n",
        "                continue\n",
        "\n",
        "            # Handle unknown words\n",
        "            elif word.strip() not in vocab:\n",
        "                orig.append(word.strip())\n",
        "                word = tagAllotement(word)\n",
        "                prep.append(word)\n",
        "                continue\n",
        "\n",
        "            else:\n",
        "                orig.append(word.strip())\n",
        "                prep.append(word.strip())\n",
        "\n",
        "    assert(len(orig) == len(open(data_fp, \"r\").readlines()))\n",
        "    assert(len(prep) == len(open(data_fp, \"r\").readlines()))\n",
        "\n",
        "    return orig, prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0n42ZNAwYMsQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pzKA2J-PZ0vM"
      },
      "outputs": [],
      "source": [
        "orig, t = preprocess(vocabulary, \"test.words\")\n",
        "best_probs, best_paths = viterbi_initialise(markovStates, countTag, transitionMatrix = transitionMatrix, emissionMatrix = emissionMatrix, corpus = t, vocab = vocabulary )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asukS7AzbnLz",
        "outputId": "8fdc1b2d-1c39-4150-c2e5-a85f1756fa6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The',\n",
              " 'economy',\n",
              " \"'s\",\n",
              " 'temperature',\n",
              " 'will',\n",
              " 'be',\n",
              " 'taken',\n",
              " 'from',\n",
              " 'several',\n",
              " '--unk--',\n",
              " 'points',\n",
              " 'this',\n",
              " 'week',\n",
              " ',',\n",
              " 'with',\n",
              " 'readings',\n",
              " 'on',\n",
              " 'trade',\n",
              " ',',\n",
              " 'output',\n",
              " ',',\n",
              " 'housing',\n",
              " 'and',\n",
              " 'inflation',\n",
              " '.',\n",
              " '--n--',\n",
              " 'The',\n",
              " 'most',\n",
              " 'troublesome',\n",
              " 'report',\n",
              " 'may',\n",
              " 'be',\n",
              " 'the',\n",
              " 'August',\n",
              " 'merchandise',\n",
              " 'trade',\n",
              " 'deficit',\n",
              " 'due',\n",
              " 'out',\n",
              " 'tomorrow',\n",
              " '.',\n",
              " '--n--',\n",
              " 'The',\n",
              " 'trade',\n",
              " 'gap',\n",
              " 'is',\n",
              " 'expected',\n",
              " 'to',\n",
              " 'widen',\n",
              " 'to',\n",
              " 'about',\n",
              " '$',\n",
              " '9',\n",
              " 'billion',\n",
              " 'from',\n",
              " 'July',\n",
              " \"'s\",\n",
              " '$',\n",
              " '7.6',\n",
              " 'billion',\n",
              " ',',\n",
              " 'according',\n",
              " 'to',\n",
              " 'a',\n",
              " 'survey',\n",
              " 'by',\n",
              " 'MMS',\n",
              " 'International',\n",
              " ',',\n",
              " 'a',\n",
              " 'unit',\n",
              " 'of',\n",
              " 'McGraw-Hill',\n",
              " 'Inc.',\n",
              " ',',\n",
              " 'New',\n",
              " 'York',\n",
              " '.',\n",
              " '--n--',\n",
              " 'Thursday',\n",
              " \"'s\",\n",
              " 'report',\n",
              " 'on',\n",
              " 'the',\n",
              " 'September',\n",
              " 'consumer',\n",
              " 'price',\n",
              " 'index',\n",
              " 'is',\n",
              " 'expected',\n",
              " 'to',\n",
              " 'rise',\n",
              " ',',\n",
              " 'although',\n",
              " 'not',\n",
              " 'as',\n",
              " 'sharply',\n",
              " 'as',\n",
              " 'the',\n",
              " '0.9',\n",
              " '%',\n",
              " 'gain',\n",
              " 'reported',\n",
              " 'Friday',\n",
              " 'in',\n",
              " 'the',\n",
              " 'producer',\n",
              " 'price',\n",
              " 'index',\n",
              " '.',\n",
              " '--n--',\n",
              " 'That',\n",
              " 'gain',\n",
              " 'was',\n",
              " 'being',\n",
              " 'cited',\n",
              " 'as',\n",
              " 'a',\n",
              " 'reason',\n",
              " 'the',\n",
              " 'stock',\n",
              " 'market',\n",
              " 'was',\n",
              " 'down',\n",
              " 'early',\n",
              " 'in',\n",
              " 'Friday',\n",
              " \"'s\",\n",
              " 'session',\n",
              " ',',\n",
              " 'before',\n",
              " 'it',\n",
              " 'got',\n",
              " 'started',\n",
              " 'on',\n",
              " 'its',\n",
              " 'reckless',\n",
              " '190-point',\n",
              " 'plunge',\n",
              " '.',\n",
              " '--n--',\n",
              " 'Economists',\n",
              " 'are',\n",
              " 'divided',\n",
              " 'as',\n",
              " 'to',\n",
              " 'how',\n",
              " 'much',\n",
              " 'manufacturing',\n",
              " 'strength',\n",
              " 'they',\n",
              " 'expect',\n",
              " 'to',\n",
              " 'see',\n",
              " 'in',\n",
              " 'September',\n",
              " 'reports',\n",
              " 'on',\n",
              " 'industrial',\n",
              " 'production',\n",
              " 'and',\n",
              " 'capacity',\n",
              " 'utilization',\n",
              " ',',\n",
              " 'also',\n",
              " 'due',\n",
              " 'tomorrow',\n",
              " '.',\n",
              " '--n--',\n",
              " 'Meanwhile',\n",
              " ',',\n",
              " 'September',\n",
              " 'housing',\n",
              " 'starts',\n",
              " ',',\n",
              " 'due',\n",
              " 'Wednesday',\n",
              " ',',\n",
              " 'are',\n",
              " 'thought',\n",
              " 'to',\n",
              " 'have',\n",
              " 'inched',\n",
              " 'upward',\n",
              " '.',\n",
              " '--n--',\n",
              " '``',\n",
              " 'There',\n",
              " \"'s\",\n",
              " 'a',\n",
              " 'possibility',\n",
              " 'of',\n",
              " 'a',\n",
              " 'surprise',\n",
              " \"''\",\n",
              " 'in',\n",
              " 'the',\n",
              " 'trade',\n",
              " 'report',\n",
              " ',',\n",
              " 'said',\n",
              " 'Michael',\n",
              " 'Englund',\n",
              " ',',\n",
              " 'director',\n",
              " 'of',\n",
              " 'research',\n",
              " 'at',\n",
              " 'MMS',\n",
              " '.',\n",
              " '--n--',\n",
              " 'A',\n",
              " 'widening',\n",
              " 'of',\n",
              " 'the',\n",
              " 'deficit',\n",
              " ',',\n",
              " 'if',\n",
              " 'it',\n",
              " 'were',\n",
              " 'combined',\n",
              " 'with',\n",
              " 'a',\n",
              " 'stubbornly',\n",
              " 'strong',\n",
              " 'dollar',\n",
              " ',',\n",
              " 'would',\n",
              " '--unk--',\n",
              " 'trade',\n",
              " 'problems',\n",
              " '--',\n",
              " 'but',\n",
              " 'the',\n",
              " 'dollar',\n",
              " 'weakened',\n",
              " 'Friday',\n",
              " 'as',\n",
              " 'stocks',\n",
              " 'plummeted',\n",
              " '.',\n",
              " '--n--',\n",
              " 'In',\n",
              " 'any',\n",
              " 'event',\n",
              " ',',\n",
              " 'Mr.',\n",
              " 'Englund',\n",
              " 'and',\n",
              " 'many',\n",
              " 'others',\n",
              " 'say',\n",
              " 'that',\n",
              " 'the',\n",
              " 'easy',\n",
              " 'gains',\n",
              " 'in',\n",
              " 'narrowing',\n",
              " 'the',\n",
              " 'trade',\n",
              " 'gap',\n",
              " 'have',\n",
              " 'already',\n",
              " 'been',\n",
              " 'made',\n",
              " '.',\n",
              " '--n--',\n",
              " '``',\n",
              " 'Trade',\n",
              " 'is',\n",
              " 'definitely',\n",
              " 'going',\n",
              " 'to',\n",
              " 'be',\n",
              " 'more',\n",
              " 'politically',\n",
              " 'sensitive',\n",
              " 'over',\n",
              " 'the',\n",
              " 'next',\n",
              " 'six',\n",
              " 'or',\n",
              " 'seven',\n",
              " 'months',\n",
              " 'as',\n",
              " 'improvement',\n",
              " 'begins',\n",
              " 'to',\n",
              " 'slow',\n",
              " ',',\n",
              " \"''\",\n",
              " 'he',\n",
              " 'said',\n",
              " '.',\n",
              " '--n--',\n",
              " 'Exports',\n",
              " 'are',\n",
              " 'thought',\n",
              " 'to',\n",
              " 'have',\n",
              " 'risen',\n",
              " 'strongly',\n",
              " 'in',\n",
              " 'August',\n",
              " ',',\n",
              " 'but',\n",
              " 'probably',\n",
              " 'not',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'offset',\n",
              " 'the',\n",
              " 'jump',\n",
              " 'in',\n",
              " 'imports',\n",
              " ',',\n",
              " 'economists',\n",
              " 'said',\n",
              " '.',\n",
              " '--n--',\n",
              " '--unk_upper--',\n",
              " 'on',\n",
              " 'manufacturing',\n",
              " 'strength',\n",
              " 'are',\n",
              " 'split',\n",
              " 'between',\n",
              " 'economists',\n",
              " 'who',\n",
              " 'read',\n",
              " 'September',\n",
              " \"'s\",\n",
              " 'low',\n",
              " 'level',\n",
              " 'of',\n",
              " 'factory',\n",
              " 'job',\n",
              " 'growth',\n",
              " 'as',\n",
              " 'a',\n",
              " 'sign',\n",
              " 'of',\n",
              " 'a',\n",
              " 'slowdown',\n",
              " 'and',\n",
              " 'those',\n",
              " 'who',\n",
              " 'use',\n",
              " 'the',\n",
              " 'somewhat',\n",
              " 'more',\n",
              " 'comforting',\n",
              " 'total',\n",
              " 'employment',\n",
              " 'figures',\n",
              " 'in',\n",
              " 'their',\n",
              " 'calculations',\n",
              " '.',\n",
              " '--n--',\n",
              " 'The',\n",
              " 'wide',\n",
              " 'range',\n",
              " 'of',\n",
              " 'estimates',\n",
              " 'for',\n",
              " 'the',\n",
              " 'industrial',\n",
              " 'output',\n",
              " 'number',\n",
              " 'underscores',\n",
              " 'the',\n",
              " 'differences',\n",
              " ':',\n",
              " 'The',\n",
              " 'forecasts',\n",
              " 'run',\n",
              " 'from',\n",
              " 'a',\n",
              " 'drop',\n",
              " 'of',\n",
              " '0.5',\n",
              " '%',\n",
              " 'to',\n",
              " 'an',\n",
              " 'increase',\n",
              " 'of',\n",
              " '0.4',\n",
              " '%',\n",
              " ',',\n",
              " 'according',\n",
              " 'to',\n",
              " 'MMS',\n",
              " '.',\n",
              " '--n--',\n",
              " 'A',\n",
              " 'rebound',\n",
              " 'in',\n",
              " 'energy',\n",
              " 'prices',\n",
              " ',',\n",
              " 'which',\n",
              " 'helped',\n",
              " 'push',\n",
              " 'up',\n",
              " 'the',\n",
              " 'producer',\n",
              " 'price',\n",
              " 'index',\n",
              " ',',\n",
              " 'is',\n",
              " 'expected',\n",
              " 'to',\n",
              " 'do',\n",
              " 'the',\n",
              " 'same',\n",
              " 'in',\n",
              " 'the',\n",
              " 'consumer',\n",
              " 'price',\n",
              " 'report',\n",
              " '.',\n",
              " '--n--',\n",
              " 'The',\n",
              " 'consensus',\n",
              " 'view',\n",
              " 'expects',\n",
              " 'a',\n",
              " '0.4',\n",
              " '%',\n",
              " 'increase',\n",
              " 'in',\n",
              " 'the',\n",
              " 'September',\n",
              " 'CPI',\n",
              " 'after',\n",
              " 'a',\n",
              " 'flat',\n",
              " 'reading',\n",
              " 'in',\n",
              " 'August',\n",
              " '.',\n",
              " '--n--',\n",
              " 'Robert',\n",
              " 'H.',\n",
              " 'Chandross',\n",
              " ',',\n",
              " 'an',\n",
              " 'economist',\n",
              " 'for',\n",
              " 'Lloyd',\n",
              " \"'s\",\n",
              " 'Bank',\n",
              " 'in',\n",
              " 'New',\n",
              " 'York',\n",
              " ',',\n",
              " 'is',\n",
              " 'among',\n",
              " 'those',\n",
              " 'expecting',\n",
              " 'a',\n",
              " 'more',\n",
              " 'moderate',\n",
              " 'gain',\n",
              " 'in',\n",
              " 'the',\n",
              " 'CPI',\n",
              " 'than',\n",
              " 'in',\n",
              " 'prices',\n",
              " 'at',\n",
              " 'the',\n",
              " 'producer',\n",
              " 'level',\n",
              " '.',\n",
              " '--n--',\n",
              " '``',\n",
              " 'Auto',\n",
              " 'prices',\n",
              " 'had',\n",
              " 'a',\n",
              " 'big',\n",
              " 'effect',\n",
              " 'in',\n",
              " 'the',\n",
              " 'PPI',\n",
              " ',',\n",
              " 'and',\n",
              " 'at',\n",
              " 'the',\n",
              " 'CPI',\n",
              " 'level',\n",
              " 'they',\n",
              " 'wo',\n",
              " \"n't\",\n",
              " ',',\n",
              " \"''\",\n",
              " 'he',\n",
              " 'said',\n",
              " '.',\n",
              " '--n--',\n",
              " 'Food',\n",
              " 'prices',\n",
              " 'are',\n",
              " 'expected',\n",
              " 'to',\n",
              " 'be',\n",
              " 'unchanged',\n",
              " ',',\n",
              " 'but',\n",
              " 'energy',\n",
              " 'costs',\n",
              " 'jumped',\n",
              " 'as',\n",
              " 'much',\n",
              " 'as',\n",
              " '4',\n",
              " '%',\n",
              " ',',\n",
              " 'said',\n",
              " 'Gary',\n",
              " '--unk_upper--',\n",
              " ',',\n",
              " 'economist',\n",
              " 'at',\n",
              " 'Fleet\\\\/Norstar',\n",
              " 'Financial',\n",
              " 'Group',\n",
              " '.',\n",
              " '--n--',\n",
              " 'He',\n",
              " 'also',\n",
              " 'says',\n",
              " 'he',\n",
              " 'thinks',\n",
              " '``',\n",
              " 'core',\n",
              " 'inflation',\n",
              " ',',\n",
              " \"''\",\n",
              " 'which',\n",
              " 'excludes',\n",
              " 'the',\n",
              " 'volatile',\n",
              " 'food',\n",
              " 'and',\n",
              " 'energy',\n",
              " 'prices',\n",
              " ',',\n",
              " 'was',\n",
              " 'strong',\n",
              " 'last',\n",
              " 'month',\n",
              " '.',\n",
              " '--n--',\n",
              " 'He',\n",
              " 'expects',\n",
              " 'a',\n",
              " 'gain',\n",
              " 'of',\n",
              " 'as',\n",
              " 'much',\n",
              " 'as',\n",
              " '0.5',\n",
              " '%',\n",
              " 'in',\n",
              " 'core',\n",
              " 'inflation',\n",
              " 'after',\n",
              " 'a',\n",
              " 'summer',\n",
              " 'of',\n",
              " 'far',\n",
              " 'smaller',\n",
              " 'increases',\n",
              " '.',\n",
              " '--n--',\n",
              " 'Housing',\n",
              " 'starts',\n",
              " 'are',\n",
              " 'expected',\n",
              " 'to',\n",
              " '--unk--',\n",
              " 'a',\n",
              " 'bit',\n",
              " 'from',\n",
              " 'August',\n",
              " \"'s\",\n",
              " 'annual',\n",
              " 'pace',\n",
              " 'of',\n",
              " '--unk_digit--',\n",
              " 'units',\n",
              " '.',\n",
              " '--n--',\n",
              " 'Economists',\n",
              " 'say',\n",
              " 'an',\n",
              " 'August',\n",
              " 'rebound',\n",
              " 'in',\n",
              " 'permits',\n",
              " 'for',\n",
              " 'multifamily',\n",
              " 'units',\n",
              " 'signaled',\n",
              " 'an',\n",
              " 'increase',\n",
              " 'in',\n",
              " 'September',\n",
              " 'starts',\n",
              " ',',\n",
              " 'though',\n",
              " 'activity',\n",
              " 'remains',\n",
              " 'fairly',\n",
              " 'modest',\n",
              " 'by',\n",
              " 'historical',\n",
              " 'standards',\n",
              " '.',\n",
              " '--n--',\n",
              " '--unk_punct--',\n",
              " 'Street',\n",
              " '--n--',\n",
              " 'If',\n",
              " 'the',\n",
              " '--unk_punct--',\n",
              " '--unk_punct--',\n",
              " 'law',\n",
              " \"'s\",\n",
              " 'fair',\n",
              " ',',\n",
              " 'Why',\n",
              " 'should',\n",
              " 'we',\n",
              " 'not',\n",
              " 'then',\n",
              " 'amend',\n",
              " 'the',\n",
              " '--unk--',\n",
              " 'To',\n",
              " 'require',\n",
              " 'that',\n",
              " 'all',\n",
              " 'employees',\n",
              " 'give',\n",
              " 'Similar',\n",
              " 'notice',\n",
              " 'before',\n",
              " 'they',\n",
              " 'quit',\n",
              " '?',\n",
              " '--n--',\n",
              " '--',\n",
              " '--unk_upper--',\n",
              " 'S.',\n",
              " '--unk_upper--',\n",
              " '.',\n",
              " '--n--',\n",
              " '--unk_upper--',\n",
              " '--unk_upper--',\n",
              " '--n--',\n",
              " 'When',\n",
              " 'research',\n",
              " 'projects',\n",
              " 'are',\n",
              " 'curtailed',\n",
              " 'due',\n",
              " 'to',\n",
              " 'government',\n",
              " 'funding',\n",
              " 'cuts',\n",
              " ',',\n",
              " 'are',\n",
              " 'we',\n",
              " '``',\n",
              " 'caught',\n",
              " 'with',\n",
              " 'our',\n",
              " 'grants',\n",
              " 'down',\n",
              " \"''\",\n",
              " '?',\n",
              " '--n--',\n",
              " '--',\n",
              " '--unk_punct--',\n",
              " 'Friedman',\n",
              " '.',\n",
              " '--n--',\n",
              " 'Assuming',\n",
              " 'the',\n",
              " 'stock',\n",
              " 'market',\n",
              " 'does',\n",
              " \"n't\",\n",
              " 'crash',\n",
              " 'again',\n",
              " 'and',\n",
              " 'completely',\n",
              " '--unk--',\n",
              " 'yuppies',\n",
              " 'and',\n",
              " 'trading',\n",
              " 'rooms',\n",
              " ',',\n",
              " 'American',\n",
              " 'television',\n",
              " 'audiences',\n",
              " 'in',\n",
              " 'a',\n",
              " 'few',\n",
              " 'months',\n",
              " 'may',\n",
              " 'be',\n",
              " 'seeing',\n",
              " 'Britain',\n",
              " \"'s\",\n",
              " 'concept',\n",
              " 'of',\n",
              " 'both',\n",
              " '.',\n",
              " '--n--',\n",
              " '``',\n",
              " 'Capital',\n",
              " 'City',\n",
              " \"''\",\n",
              " 'is',\n",
              " 'a',\n",
              " 'weekly',\n",
              " 'series',\n",
              " 'that',\n",
              " '--unk--',\n",
              " 'here',\n",
              " 'three',\n",
              " 'weeks',\n",
              " 'ago',\n",
              " 'amid',\n",
              " 'unprecedented',\n",
              " 'hype',\n",
              " 'by',\n",
              " 'its',\n",
              " 'producer',\n",
              " ',',\n",
              " '--unk_upper--',\n",
              " 'Television',\n",
              " '.',\n",
              " '--n--',\n",
              " 'The',\n",
              " 'early',\n",
              " 'episodes',\n",
              " 'make',\n",
              " 'you',\n",
              " 'long',\n",
              " 'for',\n",
              " 'a',\n",
              " '--unk--',\n",
              " 'of',\n",
              " 'the',\n",
              " 'crash',\n",
              " 'of',\n",
              " '1987',\n",
              " '.',\n",
              " '--n--',\n",
              " 'Let',\n",
              " \"'s\",\n",
              " 'make',\n",
              " 'that',\n",
              " '1929',\n",
              " ',',\n",
              " 'just',\n",
              " 'to',\n",
              " 'be',\n",
              " 'sure',\n",
              " '.',\n",
              " '--n--',\n",
              " 'According',\n",
              " 'to',\n",
              " 'the',\n",
              " 'program',\n",
              " \"'s\",\n",
              " 'publicity',\n",
              " 'prospectus',\n",
              " ',',\n",
              " '``',\n",
              " 'Capital',\n",
              " 'City',\n",
              " ',',\n",
              " \"''\",\n",
              " 'set',\n",
              " 'at',\n",
              " '--unk_upper--',\n",
              " '--unk_upper--',\n",
              " ',',\n",
              " 'a',\n",
              " '--unk--',\n",
              " '--unk_punct--',\n",
              " 'securities',\n",
              " 'firm',\n",
              " 'with',\n",
              " '#',\n",
              " '500',\n",
              " 'million',\n",
              " 'capital',\n",
              " ',',\n",
              " '``',\n",
              " 'follows',\n",
              " 'the',\n",
              " 'fortunes',\n",
              " 'of',\n",
              " 'a',\n",
              " '--unk_punct--',\n",
              " 'team',\n",
              " 'of',\n",
              " 'young',\n",
              " ',',\n",
              " '--unk_punct--',\n",
              " 'dealers',\n",
              " ',',\n",
              " 'hired',\n",
              " 'for',\n",
              " 'their',\n",
              " 'particular',\n",
              " '--unk--',\n",
              " 'of',\n",
              " 'style',\n",
              " ',',\n",
              " 'genius',\n",
              " 'and',\n",
              " 'energy',\n",
              " '.',\n",
              " '--n--',\n",
              " 'But',\n",
              " 'with',\n",
              " 'all',\n",
              " 'the',\n",
              " 'money',\n",
              " 'and',\n",
              " 'glamour',\n",
              " 'of',\n",
              " 'high',\n",
              " 'finance',\n",
              " 'come',\n",
              " 'the',\n",
              " '--unk--',\n",
              " 'pressures',\n",
              " 'to',\n",
              " 'do',\n",
              " 'well',\n",
              " ';',\n",
              " 'pressure',\n",
              " 'to',\n",
              " 'pull',\n",
              " 'off',\n",
              " 'another',\n",
              " 'million',\n",
              " 'before',\n",
              " 'lunch',\n",
              " ';',\n",
              " 'pressure',\n",
              " 'to',\n",
              " 'anticipate',\n",
              " 'the',\n",
              " 'market',\n",
              " 'by',\n",
              " 'a',\n",
              " 'fraction',\n",
              " 'of',\n",
              " 'a',\n",
              " 'second',\n",
              " '...',\n",
              " \"''\",\n",
              " '--n--',\n",
              " 'You',\n",
              " 'need',\n",
              " \"n't\",\n",
              " 'be',\n",
              " 'a',\n",
              " 'high-powered',\n",
              " 'securities',\n",
              " 'lawyer',\n",
              " 'to',\n",
              " 'realize',\n",
              " 'the',\n",
              " 'prospectus',\n",
              " 'is',\n",
              " 'guilty',\n",
              " 'of',\n",
              " 'less',\n",
              " 'than',\n",
              " 'full',\n",
              " 'disclosure',\n",
              " '.',\n",
              " '--n--',\n",
              " 'The',\n",
              " '--unk--',\n",
              " 'produced',\n",
              " 'series',\n",
              " 'has',\n",
              " 'been',\n",
              " 'criticized',\n",
              " 'by',\n",
              " 'London',\n",
              " \"'s\",\n",
              " 'financial',\n",
              " '--unk--',\n",
              " 'as',\n",
              " 'inaccurate',\n",
              " 'in',\n",
              " 'detail',\n",
              " ',',\n",
              " 'but',\n",
              " 'its',\n",
              " 'major',\n",
              " 'weakness',\n",
              " 'is',\n",
              " 'its',\n",
              " 'unrealistic',\n",
              " '--unk--',\n",
              " 'of',\n",
              " 'the',\n",
              " 'characters',\n",
              " \"'\",\n",
              " 'professional',\n",
              " 'and',\n",
              " 'private',\n",
              " 'lives',\n",
              " '.',\n",
              " '--n--',\n",
              " '--unk_upper--',\n",
              " 'loose',\n",
              " 'in',\n",
              " '--unk_upper--',\n",
              " '--unk_upper--',\n",
              " \"'s\",\n",
              " 'trading',\n",
              " 'room',\n",
              " ',',\n",
              " 'the',\n",
              " 'yuppie',\n",
              " 'dealers',\n",
              " 'do',\n",
              " 'little',\n",
              " 'right',\n",
              " '.',\n",
              " '--n--',\n",
              " 'Judging',\n",
              " 'by',\n",
              " 'the',\n",
              " 'money',\n",
              " 'lost',\n",
              " 'and',\n",
              " 'mistakes',\n",
              " 'made',\n",
              " 'in',\n",
              " 'the',\n",
              " 'early',\n",
              " 'episodes',\n",
              " ',',\n",
              " '--unk_upper--',\n",
              " '--unk_upper--',\n",
              " \"'s\",\n",
              " 'capital',\n",
              " 'should',\n",
              " 'be',\n",
              " 'just',\n",
              " 'about',\n",
              " 'exhausted',\n",
              " 'by',\n",
              " 'the',\n",
              " 'final',\n",
              " '13th',\n",
              " 'week',\n",
              " '.',\n",
              " '--n--',\n",
              " 'In',\n",
              " 'the',\n",
              " 'opening',\n",
              " 'episode',\n",
              " 'we',\n",
              " 'learn',\n",
              " 'that',\n",
              " 'Michelle',\n",
              " ',',\n",
              " 'a',\n",
              " 'junior',\n",
              " 'bond',\n",
              " 'trader',\n",
              " ',',\n",
              " 'has',\n",
              " 'indeed',\n",
              " 'pulled',\n",
              " 'off',\n",
              " 'another',\n",
              " 'million',\n",
              " 'before',\n",
              " 'lunch',\n",
              " '.',\n",
              " '--n--',\n",
              " ...]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6rjZoXWbdPN",
        "outputId": "2ae83d0d-863b-4b13-e8cd-db9f5faf4c0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3.11627192e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [7.03111906e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [4.01855762e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " ...\n",
            " [3.03449089e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [6.25173467e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [7.53917235e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(46, 34199)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(best_probs)\n",
        "\n",
        "best_probs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hvB_smvcEoJ",
        "outputId": "eb942370-9aec-4b5e-cf67-8fe7e9915cd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46\n"
          ]
        }
      ],
      "source": [
        "print(len(markovStates))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpHPaJNxcTG_"
      },
      "outputs": [],
      "source": [
        "print(type(countTag))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zucNtqM5c9tE"
      },
      "outputs": [],
      "source": [
        "print(best_paths.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ry6I-sLfe_8q"
      },
      "outputs": [],
      "source": [
        "print(best_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "rwzfuaOdVZCF"
      },
      "outputs": [],
      "source": [
        "def viterbi_forward(transitionMatrix, emissionMatrix, testingDataset, best_probs, best_paths, vocab):\n",
        "    n_tags = best_probs.shape[0]\n",
        "    for i in range(1, len(testingDataset)):\n",
        "        for j in range(n_tags):\n",
        "            best_prob_i = float('-inf')\n",
        "            best_path_i = None\n",
        "            for k in range(n_tags):\n",
        "                probability = best_probs[k,i-1]+math.log(emissionMatrix[j,vocab[testingDataset[i]]] * transitionMatrix[k,j])\n",
        "                if probability > best_prob_i:\n",
        "                    best_prob_i = probability\n",
        "                    best_path_i = k\n",
        "            best_probs[j,i]=best_prob_i\n",
        "            best_paths[j,i] = best_path_i\n",
        "    return best_probs, best_paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "HRTmnynnfbyz"
      },
      "outputs": [],
      "source": [
        "a,b = viterbi_forward(transitionMatrix, emissionMatrix, t, best_probs, best_paths, vocab = vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc_Hm2t_eJA4",
        "outputId": "006fec1d-44c7-4526-9a42-02144f21159d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5DGs5bzeqsj",
        "outputId": "7a7de8ff-bb66-452b-f66d-73afc0e9519d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 3.11627192e-05, -1.86286003e+01, -2.97661142e+01, ...,\n",
              "        -2.08549394e+05, -2.08566684e+05, -2.08570981e+05],\n",
              "       [ 7.03111906e-04, -1.75900575e+01, -3.07313922e+01, ...,\n",
              "        -2.08549347e+05, -2.08561965e+05, -2.08574779e+05],\n",
              "       [ 4.01855762e-04, -1.85358856e+01, -2.76636958e+01, ...,\n",
              "        -2.08554904e+05, -2.08561314e+05, -2.08560049e+05],\n",
              "       ...,\n",
              "       [ 3.03449089e-05, -1.83233393e+01, -2.74273555e+01, ...,\n",
              "        -2.08552924e+05, -2.08566830e+05, -2.08571127e+05],\n",
              "       [ 6.25173467e-03, -1.89980497e+01, -2.72649196e+01, ...,\n",
              "        -2.08550967e+05, -2.08559302e+05, -2.08566642e+05],\n",
              "       [ 7.53917235e-02, -1.83628846e+01, -2.84602825e+01, ...,\n",
              "        -2.08550928e+05, -2.08559425e+05, -2.08564942e+05]])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "tE-ri338Vt3R"
      },
      "outputs": [],
      "source": [
        "\n",
        "def viterbi_backward(best_probs, best_paths, corpus, states):\n",
        "    corpus_words_length = len(best_paths[0]) #number of words in the corpus  = number of columns in the best_probs and best_paths matrix\n",
        "    array_z = [None]* corpus_words_length\n",
        "    unique_pos_tag_length = len(best_probs)  #number of unique pos tags\n",
        "    last_word_best_prob = float(\"-inf\")\n",
        "    prediction_array = [None]*corpus_words_length\n",
        "    for i in range(unique_pos_tag_length):\n",
        "        if best_probs[i, -1]> last_word_best_prob:\n",
        "            last_word_best_prob = best_probs[i, -1]\n",
        "            array_z[corpus_words_length - 1] = i\n",
        "            #print(i)\n",
        "    prediction_array[corpus_words_length - 1] = states[array_z[corpus_words_length - 1]]\n",
        "    #print(prediction_array[corpus_words_length-1], prediction_array[corpus_words_length-2])\n",
        "    #print(\"Array_z\", array_z)\n",
        "    for j in range(corpus_words_length - 1, 0, -1):\n",
        "        pos_tag_for_word = array_z[j]\n",
        "        if(pos_tag_for_word!=None):\n",
        "            pos_tag_for_word = (int)(pos_tag_for_word)\n",
        "            #print(pos_tag_for_word)\n",
        "        array_z[j - 1] = best_paths[int(pos_tag_for_word), j]\n",
        "        prediction_array[j -1] = states[int(array_z[j - 1])]\n",
        "\n",
        "    return prediction_array\n",
        "    #return array_z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "MWAXcBsd4gwy"
      },
      "outputs": [],
      "source": [
        "def viterbi_backward_test(best_probs, best_paths, corpus, states):\n",
        "    corpus_words_length = len(best_paths[0]) #number of words in the corpus  = number of columns in the best_probs and best_paths matrix\n",
        "    array_z = [None]* corpus_words_length\n",
        "    unique_pos_tag_length = len(best_probs)  #number of unique pos tags\n",
        "    last_word_best_prob = float(\"-inf\")\n",
        "    prediction_array = [None]*corpus_words_length\n",
        "    for i in range(unique_pos_tag_length):\n",
        "        if best_probs[i, -1]> last_word_best_prob:\n",
        "            last_word_best_prob = best_probs[i, -1]\n",
        "            array_z[corpus_words_length - 1] = i\n",
        "            #print(i)\n",
        "    prediction_array[corpus_words_length - 1] = states[array_z[corpus_words_length - 1]]\n",
        "    #print(prediction_array[corpus_words_length-1], prediction_array[corpus_words_length-2])\n",
        "    #print(\"Array_z\", array_z)\n",
        "    for j in range(corpus_words_length - 1, 0, -1):\n",
        "        pos_tag_for_word = array_z[j]\n",
        "        if(pos_tag_for_word!=None):\n",
        "            pos_tag_for_word = (int)(pos_tag_for_word)\n",
        "            #print(pos_tag_for_word)\n",
        "        array_z[j - 1] = best_paths[int(pos_tag_for_word), j]\n",
        "        prediction_array[j -1] = states[int(array_z[j - 1])]\n",
        "\n",
        "    return array_z\n",
        "    #return array_z\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "uVRZGE82ygC0"
      },
      "outputs": [],
      "source": [
        "array_z = viterbi_backward_test(a, b, t, markovStates)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "YXsGsqpm8wZZ"
      },
      "outputs": [],
      "source": [
        "prediction_array = viterbi_backward(a, b, t, markovStates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkv034ny9ZJb",
        "outputId": "140e41d2-41f9-4db6-b97d-773e3085ca6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['see', 'them', 'here', 'with', 'us', '.', '--n--']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['VB', 'PRP', 'RB', 'IN', 'PRP', '.', '--s--']"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(t[-7:])\n",
        "prediction_array[-7:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHxtPomV95Y0",
        "outputId": "c2cd26fe-4c08-487c-ade2-52f784df351b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "third word is temperature\n",
            "prediction is NN\n",
            "label is temperature\tNN\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"third word is\", t[3])\n",
        "print(\"prediction is\", prediction_array[3])\n",
        "print(\"label is\", testingDataset[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "1EmnmShd-1Qp"
      },
      "outputs": [],
      "source": [
        "#accuracy prediction\n",
        "def get_accuracy(prediction_array, testingDataset):\n",
        "    correct_observations = 0\n",
        "    total_observations = 0\n",
        "\n",
        "    for i,j in zip(prediction_array, testingDataset):\n",
        "        dataset_word_splitted = j.split()\n",
        "        testing_word_length = len(dataset_word_splitted)\n",
        "        if(testing_word_length != 2):\n",
        "            continue\n",
        "        word = dataset_word_splitted[0]\n",
        "        tag = dataset_word_splitted[1]\n",
        "        if i == tag:\n",
        "            correct_observations += 1\n",
        "        total_observations += 1\n",
        "    return correct_observations/total_observations * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iFKuEPJApdI",
        "outputId": "4302a041-ee93-4010-8d25-de1a95513f8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy percentage is 95.3063647155511\n"
          ]
        }
      ],
      "source": [
        "print(\"accuracy percentage is\", get_accuracy(prediction_array, testingDataset))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of POS_tagging.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
